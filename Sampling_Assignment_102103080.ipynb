{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0bbc15",
   "metadata": {},
   "source": [
    "# Sampling Assignment 102103080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f5fb8",
   "metadata": {},
   "source": [
    "### Step 1: Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c30c02c-a28e-429b-be49-d8178158ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.12.0-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 0.0/257.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/257.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/257.7 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 81.9/257.7 kB 762.6 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 143.4/257.7 kB 944.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 245.8/257.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 257.7/257.7 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9543f9e-0638-4baf-a49b-c8170d2fda53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yessica tuteja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c75d91-097c-479d-a5d9-a0aaf4ac498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspecNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "   ---------------------------------------- 0.0/169.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/169.0 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/169.0 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 30.7/169.0 kB 325.1 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 41.0/169.0 kB 281.8 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 112.6/169.0 kB 656.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 169.0/169.0 kB 782.0 kB/s eta 0:00:00\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2023.12.2\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f3de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f39ad6",
   "metadata": {},
   "source": [
    "### Step 2: CREATING Dataframe and Sampling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4686bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C://Users//Yessica Tuteja//OneDrive//Desktop//sem//sem5//ML-Datasets//Creditcard_data.csv\")\n",
    "X_df = df.drop(\"Class\", axis=1)\n",
    "y_df = df[\"Class\"]\n",
    "rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "tom = TomekLinks(sampling_strategy='majority')\n",
    "smote = SMOTE()\n",
    "nm = NearMiss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058c09e",
   "metadata": {},
   "source": [
    "### Step 3: Generating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b051a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (772, 30) (772,)\n",
      "Random Undersampling: (18, 30) (18,)\n",
      "Random Oversampling: (1526, 30) (1526,)\n",
      "Tomek Links: (765, 30) (765,)\n",
      "SMOTE: (1526, 30) (1526,)\n",
      "Near-Miss: (18, 30) (18,)\n"
     ]
    }
   ],
   "source": [
    "X_rus, y_rus = rus.fit_resample(X_df, y_df)\n",
    "X_ros, y_ros = ros.fit_resample(X_df, y_df)\n",
    "X_tom, y_tom = tom.fit_resample(X_df, y_df)\n",
    "X_smote, y_smote = smote.fit_resample(X_df, y_df)\n",
    "X_nm, y_nm = nm.fit_resample(X_df, y_df)\n",
    "\n",
    "print(\"Original dataset:\", X_df.shape, y_df.shape)\n",
    "print(\"Random Undersampling:\", X_rus.shape, y_rus.shape)\n",
    "print(\"Random Oversampling:\", X_ros.shape, y_ros.shape)\n",
    "print(\"Tomek Links:\", X_tom.shape, y_tom.shape)\n",
    "print(\"SMOTE:\", X_smote.shape, y_smote.shape)\n",
    "print(\"Near-Miss:\", X_nm.shape, y_nm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56207ff",
   "metadata": {},
   "source": [
    "### Step 4: Performing Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b282b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_test_split(X, y):\n",
    "    return train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_rus_train, X_rus_test, y_rus_train, y_rus_test = do_train_test_split(X_rus, y_rus)\n",
    "X_ros_train, X_ros_test, y_ros_train, y_ros_test = do_train_test_split(X_ros, y_ros)\n",
    "X_tl_train, X_tl_test, y_tl_train, y_tl_test = do_train_test_split(X_tom, y_tom)\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = do_train_test_split(X_smote, y_smote)\n",
    "X_nm_train, X_nm_test, y_nm_train, y_nm_test = do_train_test_split(X_nm, y_nm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86150",
   "metadata": {},
   "source": [
    "### Step 5: Preparing ML Models and Sample datasets for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c043f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM Classifier': SVC(kernel='rbf'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    ('Random Undersampling', X_rus_train, y_rus_train, X_rus_test, y_rus_test),\n",
    "    ('Random Oversampling', X_ros_train, y_ros_train, X_ros_test, y_ros_test),\n",
    "    ('Tomek Links', X_tl_train, y_tl_train, X_tl_test, y_tl_test),\n",
    "    ('SMOTE', X_smote_train, y_smote_train, X_smote_test, y_smote_test),\n",
    "    ('Near-Miss', X_nm_train, y_nm_train, X_nm_test, y_nm_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafedb9b",
   "metadata": {},
   "source": [
    "### Step 6: Finding and Storing Resultant accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12538edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yessica Tuteja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Yessica Tuteja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Yessica Tuteja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Yessica Tuteja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Yessica Tuteja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM Classifier</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Undersampling</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Oversampling</th>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.984293</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.997382</td>\n",
       "      <td>0.992147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tomek Links</th>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.916230</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>0.672775</td>\n",
       "      <td>0.992147</td>\n",
       "      <td>0.984293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Near-Miss</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Logistic Regression  Decision Tree  SVM Classifier  \\\n",
       "Random Undersampling             0.200000       0.400000        0.000000   \n",
       "Random Oversampling              0.910995       0.984293        0.685864   \n",
       "Tomek Links                      0.989583       0.984375        0.989583   \n",
       "SMOTE                            0.916230       0.973822        0.672775   \n",
       "Near-Miss                        0.000000       0.000000        0.000000   \n",
       "\n",
       "                      Random Forest  Gradient Boosting  \n",
       "Random Undersampling       0.400000           0.400000  \n",
       "Random Oversampling        0.997382           0.992147  \n",
       "Tomek Links                0.989583           0.984375  \n",
       "SMOTE                      0.992147           0.984293  \n",
       "Near-Miss                  0.000000           0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model_results = {}\n",
    "    for dataset_name, X_train_ds, y_train_ds, X_test_ds, y_test_ds in datasets:\n",
    "        model.fit(X_train_ds, y_train_ds)\n",
    "        y_pred = model.predict(X_test_ds)\n",
    "        accuracy = accuracy_score(y_test_ds, y_pred)\n",
    "        model_results[dataset_name] = accuracy\n",
    "    results[model_name] = model_results\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"C://Users//Yessica Tuteja//Downloads//sampling_model_102103080.csv\", index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6247cf06-3665-4d95-a874-bbc5d3228e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Sampling Method for Each Model:\n",
      "                         Sampling Method  Accuracy\n",
      "Logistic Regression          Tomek Links  0.989583\n",
      "Decision Tree                Tomek Links  0.984375\n",
      "SVM Classifier               Tomek Links  0.989583\n",
      "Random Forest        Random Oversampling  0.997382\n",
      "Gradient Boosting    Random Oversampling  0.992147\n"
     ]
    }
   ],
   "source": [
    "best_results = {}\n",
    "for model in results_df.columns:\n",
    "    best_sampling = results_df[model].idxmax()\n",
    "    best_accuracy = results_df[model].max()\n",
    "    best_results[model] = {'Sampling Method': best_sampling, 'Accuracy': best_accuracy}\n",
    "best_df = pd.DataFrame(best_results).T\n",
    "\n",
    "print(\"\\nBest Sampling Method for Each Model:\")\n",
    "print(best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da03923e-b089-4185-abf4-648efc61dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.to_csv(\"C://Users//Yessica Tuteja//Downloads//Best_Sampling_102103080.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76083444-117b-4bc0-8640-255a8c6fc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
